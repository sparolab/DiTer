## News!
* **After the review is complete, we plan to release the new version.**
* **Finally, our paper is accepted in IEEE Sensor Letter!!**
	* We will provide the final citation once the paper is published.


## DiTer
* **DiTer: Diverse Terrain and Multi-Modal Dataset for Field Robot Navigation in Outdoor Environments**
	* Accepted in IEEE Sensors Letter 2023

* **Sensor Configuration** 
	* We configure the legged robot with various sensors offered in multi-session datasets.
<p align="center"><img src=fig/sensor_setup.png /></p>

## Example Sequence in HILL01-A
	* Our perceptual sensor data.
<p align="center"><img src=fig/sensor.gif /></p>

## Calibration
	* Using the [camera-lidar calibration toolbox](https://github.com/acfr/cam_lidar_calibration), we calibrate camera-LiDAR and thermal-LiDAR.
	* Due to the opposite nature of heat and color characteristics, we proceed by inverting the thermal image.
<p align="center"><img src=fig/calibration.png /></p>

## Trajectory
	* Utilizing the [FAST-LIO](https://github.com/hku-mars/FAST_LIO), we provide a reference trajectory. 
	* Also, the resulting map can also be examined as follows
<p align="center"><img src=fig/trajectory.png /></p>
<p align="center"><img src=fig/map.png /></p>

## Cite DiTer
<pre>
<code>
@article{jeongditer,
  title={DiTer: Diverse Terrain and Multi-Modal Dataset for Field Robot Navigation in Outdoor Environments},
  author={Jeong, Seokhwan and Kim, Hogyun and Cho, Younggun}
}
</code>
</pre>  

## Contact
* **Seokhwan Jeong (eric5709@inha.edu)**
* **Hogyun Kim (hg.kim@inha.edu)**

## Supplementary
* **[Google Sites](https://sites.google.com/inha.edu/diter/)**
* **[Youtube](https://www.youtube.com/watch?v=i-2FwYKT5ss)**

